{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataframe has 1395156 rows.\n"
     ]
    }
   ],
   "source": [
    "# convert all of the cn a folder to one csv with duplicates dropped\n",
    "def hist_csvs_to_csv(csv_folder, csv_file):\n",
    "    # Read all CSVs from folder\n",
    "    csvs = [f\"{csv_folder}/{i}\" for i in os.listdir(csv_folder)]\n",
    "    dfs = [pd.read_csv(csv) for csv in csvs]\n",
    "\n",
    "    # Grab required columns first\n",
    "    cols = [\"CARDOFFICE_CARD_NUMBER\", \"CARD_ID_STATUS\", \"RIDE_DATE\", \"ROUTE\", \"EMPLOYEE_OR_STUDENT\", \"CAMPUS_ID\"]\n",
    "    dfs = [df[cols] for df in dfs]\n",
    "\n",
    "    # Concatenate all dataframes and drop duplicates early\n",
    "    df = pd.concat(dfs).drop_duplicates()\n",
    "\n",
    "    # Filter rows where CARD_ID_STATUS is not UNKNOWN\n",
    "    df = df[df[\"CARD_ID_STATUS\"] != \"UNKNOWN\"]\n",
    "\n",
    "    # Add derived columns\n",
    "    df[\"RIDE_DATE\"] = pd.to_datetime(df[\"RIDE_DATE\"], format=\"mixed\")\n",
    "    df[\"MONTH_YEAR\"] = df[\"RIDE_DATE\"].dt.strftime('%Y-%m')\n",
    "    df[\"HOUR\"] = df[\"RIDE_DATE\"].dt.hour\n",
    "\n",
    "    # Save to output CSV\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"Final dataframe has {len(df)} rows.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    hist_csvs_to_csv(\"./data/historical\", \"../public/data/historical_card_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-01 06:54:00+00:00 2024-11-29 22:50:47+00:00\n",
      "(1395156, 8)\n"
     ]
    }
   ],
   "source": [
    "# give me the min and max date of the data\n",
    "def min_max_date(df):\n",
    "    min_date = df[\"RIDE_DATE\"].min()\n",
    "    max_date = df[\"RIDE_DATE\"].max()\n",
    "    return min_date, max_date\n",
    "\n",
    "# import the csv\n",
    "df = pd.read_csv(\"../public/data/historical_card_data.csv\")\n",
    "min_date, max_date = min_max_date(df)\n",
    "print(min_date, max_date)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1395156\n"
     ]
    }
   ],
   "source": [
    "# print out length of data\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999072, 8)\n"
     ]
    }
   ],
   "source": [
    "# print size of the data\n",
    "# import historical data from csv\n",
    "df2 = pd.read_csv(\"./data/historical_data.csv\")\n",
    "df3 = pd.read_csv(\"./data/historical/historical_card_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999072, 8)\n"
     ]
    }
   ],
   "source": [
    "print(df3.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickticket processing\n",
    "# read all the csvs in the quickticket folder and convert them to one csv\n",
    "# convert all of the csvs in a folder to one csv with duplicates dropped\n",
    "def qt_csvs_to_csv(csv_folder, csv_file):\n",
    "    csvs = [f\"{csv_folder}/{i}\" for i in os.listdir(csv_folder)]\n",
    "    dfs = [pd.read_csv(csv) for csv in csvs]\n",
    "    # grab certain columns and drop duplicates\n",
    "    cols = [\"Card Office Card Number\",\"Campus/VUNetID\",\"Ride Date\",\"Route\"]\n",
    "    # add a column for MONTH_YEAR\n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i] = dfs[i][cols]\n",
    "        # rename these columns\n",
    "        dfs[i].columns = [\"CARDOFFICE_CARD_NUMBER\", \"CAMPUS_ID\", \"RIDE_DATE\", \"ROUTE\"]\n",
    "        dfs[i][\"RIDE_DATE\"] = pd.to_datetime(dfs[i][\"RIDE_DATE\"])\n",
    "        dfs[i][\"MONTH_YEAR\"] = dfs[i][\"RIDE_DATE\"].dt.strftime('%Y-%m')\n",
    "        # list all columns\n",
    "        print(dfs[i].columns)\n",
    "    df = pd.concat(dfs).drop_duplicates()\n",
    "    # convert any ROUTE value == \"Vandy Vans\" to \"Vandy Vans\"\n",
    "    df.loc[df[\"ROUTE\"] == \"Riverfront Station\", \"ROUTE\"] = 100\n",
    "    df.loc[df[\"ROUTE\"] == \"Donelson Station\", \"ROUTE\"] = 101\n",
    "    df.loc[df[\"ROUTE\"] == \"Hermitage Station\", \"ROUTE\"] = 102\n",
    "    df.loc[df[\"ROUTE\"] == \"Mt. Juliet Station\", \"ROUTE\"] = 103\n",
    "    df.loc[df[\"ROUTE\"] == \"Martha Station\", \"ROUTE\"] = 104\n",
    "    df.loc[df[\"ROUTE\"] == \"Hamilton Springs Station\", \"ROUTE\"] = 105\n",
    "    df.loc[df[\"ROUTE\"] == \"Lebanon Station\", \"ROUTE\"] = 106\n",
    "    \n",
    "    df['CARDOFFICE_CARD_NUMBER'] = pd.to_numeric(df['CARDOFFICE_CARD_NUMBER'], errors='coerce')\n",
    "\n",
    "    df['CARDOFFICE_CARD_NUMBER'] = df['CARDOFFICE_CARD_NUMBER'].fillna(-1).astype(\"int64\")\n",
    "\n",
    "    # Check the data again to ensure the conversion\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # drop any rows with missing values\n",
    "    df = df.dropna()\n",
    "    print(df.columns)\n",
    "    df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CARDOFFICE_CARD_NUMBER', 'CAMPUS_ID', 'RIDE_DATE', 'ROUTE',\n",
      "       'MONTH_YEAR'],\n",
      "      dtype='object')\n",
      "Index(['CARDOFFICE_CARD_NUMBER', 'CAMPUS_ID', 'RIDE_DATE', 'ROUTE',\n",
      "       'MONTH_YEAR'],\n",
      "      dtype='object')\n",
      "Index(['CARDOFFICE_CARD_NUMBER', 'CAMPUS_ID', 'RIDE_DATE', 'ROUTE',\n",
      "       'MONTH_YEAR'],\n",
      "      dtype='object')\n",
      "Index(['CARDOFFICE_CARD_NUMBER', 'CAMPUS_ID', 'RIDE_DATE', 'ROUTE',\n",
      "       'MONTH_YEAR'],\n",
      "      dtype='object')\n",
      "Index(['CARDOFFICE_CARD_NUMBER', 'CAMPUS_ID', 'RIDE_DATE', 'ROUTE',\n",
      "       'MONTH_YEAR'],\n",
      "      dtype='object')\n",
      "CARDOFFICE_CARD_NUMBER             int64\n",
      "CAMPUS_ID                         object\n",
      "RIDE_DATE                 datetime64[ns]\n",
      "ROUTE                             object\n",
      "MONTH_YEAR                        object\n",
      "dtype: object\n",
      "Index(['CARDOFFICE_CARD_NUMBER', 'CAMPUS_ID', 'RIDE_DATE', 'ROUTE',\n",
      "       'MONTH_YEAR'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    qt_csvs_to_csv(\"./data/quickticket\", \"./data/quickticket.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CAMPUS_ID  RIDE_DATE  ROUTE MONTH_YEAR\n",
      "0    dengz2 2024-07-01      7    2024-07\n",
      "1   dingay1 2024-07-01     17    2024-07\n",
      "2   madrige 2024-07-01     50    2024-07\n",
      "3    dengs2 2024-07-02      3    2024-07\n",
      "4    dengz2 2024-07-02      7    2024-07\n",
      "2024-07-01 00:00:00 2024-11-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# import the csv\n",
    "qt_df = pd.read_csv(\"../public/data/quickticket_data.csv\")\n",
    "# convert to datetime\n",
    "qt_df[\"RIDE_DATE\"] = pd.to_datetime(qt_df[\"RIDE_DATE\"])\n",
    "print(qt_df.head())\n",
    "min_date = qt_df[\"RIDE_DATE\"].min()\n",
    "max_date = qt_df[\"RIDE_DATE\"].max()\n",
    "print(min_date, max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "input_path = './data/quickticket.csv'\n",
    "output_path =  '../public/data/quickticket_data.csv'\n",
    "\n",
    "with open(input_path, 'r', newline='') as infile, open(output_path, 'w', newline='') as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    for row in reader:\n",
    "        # Write out rows, skipping the first column\n",
    "        writer.writerow(row[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33679\n"
     ]
    }
   ],
   "source": [
    "# print out length of data\n",
    "print(len(qt_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vanderbilt_movevu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
